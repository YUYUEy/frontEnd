### 存储与检索

#### 目的： 对数据库的实现有一个宏观的认识。

自己的知识储备太少了。。导致读起来的时候需要去看很多东西。主要目的是对这些有一个宏观点的认识，把握这个原则不去陷的太深。

数据库做了什么？

1.给它数据，它给保存起来     
2.对数据库说明要什么数据，数据库返回数据


数据库的简单实现：

    def db_set(key, value):
        write(key, value)
    
    def db_get(key):
        for kv in db(这里是逆序的):
            if kv.key = key:
               return kv.value

这是一个最简单的键值存储的功能。 实现很简单，就是把每一个key value 追加写入到   
数据库中。每次对一个相同的key的写入都不会覆盖旧的key，查询最新的值的时候就是
从后往前找第一个。这样子的好处是写入的时候非常高效（append only的）。

但是上面这种方式的坏处是查找的时候复杂度是O（n），并且这个N是随着插入数据的大小
而变化的。当n扩大一倍，查找花费的时间也就扩大了一倍。


解决上面这个问题的办法是添加索引。这种方式在写入的时候会增加一些开销。而且并不是
所有的数据都需要加索引的。这里就需要判断那些数据是有必要加索引的。


常用的索引。

哈希索引：
在数据结构课中学过哈希表。本质上就是通过空间来换时间。查找的速度是O（1），

在上面那个最简单的数据库中使用哈希索引的方式如下：

![base](http://pyblog-10073407.image.myqcloud.com/postimage1520733720?imageView2/0/w/450/h/400 "enter image title here")



通过维持一个hash表记录了key的偏移量。查询的时候可以直接找到这个位置将数据读取出来。

一个问题，如果每次都将数据加入磁盘，怎么避免磁盘空间被占满。

解决的方式是给这个文件设置一个大小值，如果超过这个大小就重新开启一个文件。然后对文件进行合并。将最新的数据保留下来。

如图：   

![2](http://pyblog-10073407.image.myqcloud.com/postimage1520733732?imageView2/0/w/450/h/400 "enter image title here")





类似与归并的思路。合并可以放在后台执行。
这里每一段文件都是有自己的hash表的。查询的时候从最近的开始，如果最近没有则从下一个更近的开始。会遇到的一些问题：

文件的格式问题： 二进制的格式要比csv 的更快

删除一个key的时候，需要保存这个删除记录。 在合并的时候放弃删除的这个key之前的值

崩溃恢复： 数据库重启，需要重新加载内存hash表。
Bitcask通过保存线索文件来加速重建hash表。这个线索文件是通过保存文件的位置来加速的。

部分写入记录 数据库可能随时崩溃。 bitcask 通过校验和来检查无效的数据

并发控制。
 写操作是按照顺序写入的，常见的实现是一个写入的线程，多个读取的线程。
回到一开始的实现，为什么要追加写入而不是更新呢？

	1. 追加 分段合并是顺序写入，要比随机写入快（尤其是在机械硬盘。ssd上顺序写入也是好处要更多的）
	2. 这些分段的文件是append only 或者 immutable，不需要担心覆盖值崩溃的情况
	3. 合并旧的数据段避免数据文件分散。

    局限
散列表大小取决于内存大小，而在磁盘保存散列表随机io很多，效率很低
对区间支持不好。比如一个用户表中，查找年龄大于20岁的。如果用hash的话就需要将每个大于20的进行一次映射。

一种去掉了上述限制的实现

SSTables和LSM-Trees

上图提到的实现方法是不考虑文件中的键值对的顺序的，而且一个文件会有多个键值对（键相同）。新的文件中的值优与旧的。

sstable sorted string table
这种结构要求对key进行排序，并且每一段文件一个键只出现一次。 和上面的这种方式相比优势主要是：

![enter image description here](http://pyblog-10073407.image.myqcloud.com/postimage1520733741?imageView2/0/w/450/h/400 "enter image title here")


1.如图， 合并的时候文件即使大于内存，也可以并排读取文件（类似于归并排序）。每个段都是保存特定时间的值，如果有重复的 以最新的为准。

![index](http://pyblog-10073407.image.myqcloud.com/postimage1520733748?imageView2/0/w/450/h/400 "enter image title here")

2.不需要保存全部的key的索引，只需要保存几个键的索引即可。通过区间搜索可以找到需要的值。（这里的思路应该是用一点点时间来换取了空间。）
3.上面的那种方法写入磁盘的时候并没有对数据进行压缩。这种方法每写入一次都要进行一次压缩。降低了io。

构建维护sstable
我们的数据写入的时候可能是任何顺序，如何来维持一个有序的结构呢？

1.写入的时候通过平衡树数据结构在内存维护一个树（memtable）
2.设定一个值，超过这个值就将这个文件（memtable）写入磁盘
3.读取的时候从最新的开始读取，如果最新的没读到就去最近的读取
4.合并 压缩时候将一些旧的数据删除

这种方式的问题是数据库挂掉，最近的写入就丢了（没有写入磁盘的memtable）
解决问题是维护一个单独的日志保存这个。


基于压缩和排序文件原理的存储引擎就是lsm存储引擎。



elasticsearch 和 solr 的索引引擎也是类似的思路，实现方式是这样子的将搜索的一个单词
和包含单词的所有文档id用sstable表保存起来，并按照需求合并。


**性能优化**

如果查找的数据不在数据库中，查找会很慢（因为需要一层一层去旧的数据哪里寻找）。
针对这个通过布隆过滤器来实现。
python中的一个很好的实现。
https://github.com/jaybaird/python-bloomfilter/blob/master/pybloom/pybloom.py


判断一个元素在不在一个集合中有几种方法  链表，树，哈希。 复杂度是O(n) O(logn)O(1)
布隆过滤器原理是通过几个hash函数将这个元素映射成几个点。在位图中将这个点变为1，搜索的时候看这个点是不是1.     
缺点是有一定的误算率。不过很小

sstable 压缩和合并。。

B树是一种矮胖型的树（之所以是矮胖型是为了减少磁盘seek次数），在数据库中应用广泛。

首先和sstable一样的是，b树也是保持有序的键值对。但是和上面的日志结构的索引不同的是
这里每个块大小是一样的。这种设计的好处是和底层紧密相连（磁盘的块大小也是固定的）。

![](http://pyblog-10073407.image.myqcloud.com/postimage1520733753?imageView2/0/w/450/h/400 "enter image title here")

如图，上面的节点是放在磁盘中的。如果使用二叉树这个树会变得很高，seek次数会很多。
分支因子指的是最上一层树的宽度。上图为6。大多数数据库都可以在三四层内。

可靠性。和上面的lsm相比，这种类型的数据库是覆盖数据，而不是追加写入数据。

写时放大指的是在ssd中写入一小块数据也需要对一大块空间擦除，写入。


B树 VS LSM树

B树要想写入一段数据的话需要最少写两次。 一次是日志，一次是树页。
LSM 是按照顺序写入sstable文件，而不是覆盖，这导致了是顺序写入的，写入的
速度会很快。

LSM 这种结构在压缩的时候可能会干扰正在进行的读写操作。

B树的每个键只保持在索引的一个位置，而LSM的多个段的多个副本。这使得B树做事务的时候很好。

**其它索引
**
聚集索引： 在索引中保存所有行的数据
非聚集索引： 索引中只保存对数据的引用
覆盖索引： 一部分数据在索引中，一部分是通过引用


多列索引
之前的索引都是只在一个列上作用的，现在需求是要对两列进行一个索引。比如查询一个地理位置，查询一个经纬度范围内的。    
 一种方法是将二维变为一维。 另一种是通过特殊化 的空间索引。 （R树 https://zh.wikipedia.org/wiki/R%E6%A0%91，核    
 心思路就是将距离相近的节点聚合在一块，查找某个范围内的时候找这个包含俩节点的块）



内存数据库

这里有意思的一点是内存数据库性能的优势并不是因为数据保存在内存上，而不是磁盘上。操作系统也会缓存一些磁盘块在内存中     
（可能有的数据不会从磁盘获取），内存的性能优势来自于省去了内存数据结构变为磁盘数据结构的开销。









