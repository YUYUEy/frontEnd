### DDIA（5）

#### 复制


本章读完后会了解到**复制的主要作用， 常见的复制模式，不同模式间的优缺点 以及如何来解决这些问题**    

#### 为什么要复制，复制有什么好处？

* 减少用户和服务系统间的延迟
* 由于复制后的数据是多份的，复制后可以提高可用性
* 很多应用的特征是读多写少，可以通过复制来提高吞吐

#### 常见的复制模式

* 主从
* 主主
* 无主

**主从**

这种模式是有一个主数据库，所有的写入会在这个数据库完成。其它的数据库会和主库进行同步，保证数据是最新的。
工作原理是这样子的，当客户端一个请求过来，找到主库，将数据写入主库。然后主库将数据更新到从库。查询的时候
可以只向从库读，减轻主库压力。

这里就牵出一堆问题。 **同步复制与异步复制**

同步复制：

主库在处理用户的请求的时候使用同步复制，在响应返回之前会将数据更新到从库，在从库更新完后才将响应返回给用户。
这种好处显而易见， 从库的数据和主库的相同的，用户从 从库也可以看到最新的数据。如果主库跪了，在从库可以看到
最新的数据。

但是这种方式的坏处也是很致命的，如果由于网络原因 或者是从库跪了主库就无法完成响应。整个服务就卡在了这里，造成
服务不可用。

半同步：

这种方法的思路是将同步和异步混用，在系统中保证有一个从库是同步的， 系统中有两个库是有最新的数据的。

异步复制：

这种方式的好处是系统不会被一个节点给卡主，但是可能会出现数据不一致，主库挂掉 而从库又没有更新数据造成数据丢失。


**添加新的从库**

如何添加新的从库，替换挂掉的节点，保证从库和主库的数据是一致的？

数据的在一直变化的，这就导致数据的副本在不同的时刻是不同的。可以很容易想到，通过将数据库锁起来（禁止写入），来保
证数据是一致的，就像操作系统中对文件进行保护一样。这种方式损失了可用性。

一种方式是 获得数据库的快照，将快照更新到 数据库。

**现在某个从库/主库挂了怎么办？**

从库挂掉：

一方面从库挂掉需要将请求转移到其它节点，另外一方面需要将数据更新到和从库一样的状态上。

主库挂掉：

主库挂掉的话会麻烦很多，需要将一个从库变为主库，并且通知其它从库我现在是主库了。同时当之前挂了的主库恢复后
要知道自己现在变成从库了。  

1. 判断主库挂掉了，这个可以通过超时来判断。如果多久没响应就挂了。
2. 将一个拥有最新数据副本的从库变为主库，这里需要选出一个库，让所有从库认为它是新的主库。
3. 将客户端的请求变更到新的主库上，并且之前的主库恢复后要明白自己变成了从库。

在故障转移的时候也会有很多问题：

1. 使用异步复制的时候，新的库可能会丢一些数据。当老的主库重新加入后可能有冲突的请求。
2. 数据库和其它系统有耦合， 作者在这里举了一个github的例子，一个旧的从库被提升为主库， 
    这个从库的数据和主库的数据是不同步的，数据库用自增id为主键，在使用了新的主库后，重用
    了一些已经用过的主键，这些主键在redis中被使用，这就导致那些被用过的主键可以从redis中
    获取其它用户的隐私数据。

3. 主库失效时间要如何权衡？ 时间太短可能会有很多不必要的故障转移，如果时间太长 可能导致恢复时间也变长
   

**复制日志**

**基于语句的复制**

将语句转发到从库，可能出现的问题是 语句中使用了一些 "变量"（比如 当前时间戳）， 或者语句中的数据是有依赖的（自增id）。 

* 传输预写式日志

在任何一种情况下，日志都是包含所有数据库写入的仅追加字节序列。可以使用完全相同的日志在另一个节点上构建副本：    
除了将日志写入磁盘之外，主库还可以通过网络将其发送给其从库。这种方式是和存储引擎耦合的。

当从库应用这个日志时，它会建立和主库一模一样数据结构的副本。

* 逻辑日志复制   

复制 和 存储引擎使用不同的格式，将数据和存储引擎解耦。    

#### 复制延迟

对使用异步复制系统进行扩展的时候只需要添加从节点就可以，但是数据会不一致。使用同步的时候可能会在一个节点block掉整个系统

写后读：  

一种场景是 用户更新自己的签名，更新后想立马看到，但是其他用户不需要立马看到。

对于这种情况当用户提交数据的时候提交到主库，查看的时候可以也直接从主库读取。这种情况只适用于用户只编辑少部分内容的情况。
另一种方式是通过一个逻辑时间戳来保证，在客户端这里保存最后一次写入的时间戳，用这个来进行对比。

还需要考虑的几点是：   

用了多个数据中心，请求需要路由到主库的数据中心。
在跨设备请求中间保证一致。这种情况下时间戳的方法是无法使用的。并且在多个数据中心的情况下不同的设备路由到一个数据中心会很麻烦。     

#### 单调读取
**使用异步复制的时候，延迟可能有较大的差别。可能造成的一种情况是一个请求先到了一个延迟小的服务器，拿到了想要的数据，然后又请求到
了另一个延迟大服务器 ，延迟大的服务器数据还没有更新，第二个请求就没有想要的数据返回。**

一种方式是将同一个用户的请求转发到同一个服务器，可以通过将用户的id hash到一个服务器上。但是这个服务器也可能挂掉，
这时就要考虑另一种方法。

一种办法是确保有依赖的数据写入一个分区。

### 多主复制

**场景一，使用多个数据中心**

先来看使用单主+多个数据中心，每个请求都要通过外网。会增加延迟。是一种不好的方法。

多主+多个数据中心， 各个数据中心处理自己的中心的请求，无需通过外网，减少了延迟，在网络上可靠性也会   
高很多。在数据中心间进行异步复制。

缺点是可能会同时处理同一个，需要一种手段来解决这种问题，有点类似于操作系统中临界区的概念。

**场景二，离线操作**

常见的印象笔记，不联网也可以使用，联网后可以自己进行数据同步。每一个客户端就是一个主库。更新数据的
时间完全取决于什么时候联网。。

另一种和上面类似的操作，**协同编辑**

常见的有石墨文档，google 文档，本质上这就是一个读者写者问题，在一个用户进行编辑的时候就拿到一个锁，
持有这个锁的时候用户可以进行写入，这个锁的粒度可以自己定义，粒度越小 协同的效率可能会越高


#### 解决写入冲突的问题

可能的一种情况是两个用户同时编辑一个公共的东西。用户1 将A 变为B， 用户2 将A 变为C。
在单主的时候只需要将第二个请求给block掉就可以了。

在多主的时候需要冲突合并。具体的策略需要根据实际系统的情况来选择。 
一种方式是LWW，只认准最后写入的.但是这种方式可能会丢数据

写时执行- 当数据写入的时候检查是否冲突，如果冲突后调用冲突解决程序。

读时执行- 读取的时候给用户显示多份，将逻辑在应用程序层面做。

#### 复制拓扑

和网络中的拓扑的概念一样，有星形， 环形， 网形。 

星形， 环形 中的一个节点发生问题，会中断掉其它节点。

在比较密集的链接中可能会因为网络问题造成一些问题。
例如 A 向 DB1 写入一个数据， 向DB2（DB2阻塞了） DB3 同步数据， B请求到DB3 更新刚才A写入的数据，将这个写入更新到
DB2中，这时DB2中并没有这个数据，更新它就会出现问题。

这里就有一个因果关系的问题，更新数据取决于插入数据，这里就需要一些手段来维持这个顺序。

#### 无主复制

写入的时候写入多个副本，有一个控制写入的节点来将正确的数据写入。

* 一个节点发生故障

在无主的时候一个节点发生故障并不影响，比如写入一个数据到三个副本，两个副本成功了。并不需要关心哪一个失败的
当这个出现问题的节点重新启动，如何来保证这里读取的数据是没问题的？

**读修复**
读取的时候读多个节点，如果一些节点产生了有问题的数据则将正确的数据写入

另一种方式是通过一个后台进程来不断轮询这些数据，发现这些数据的差别，将有问题的数据修复。

* 如何来判断拿到的数据是正确的？















































